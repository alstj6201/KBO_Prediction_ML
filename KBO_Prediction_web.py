# í•„ìš”í•œ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import ollama  # â† Ollama ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¡œì»¬ LLM ì‹¤í–‰ì„ ìœ„í•œ)
import streamlit as st  # â† Streamlit ì›¹ì•± í”„ë ˆì„ì›Œí¬

# ğŸ“Œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜ ì •ì˜
def init_session_state(keys: dict):
    for key, value in keys.items():
        if key not in st.session_state:  # â† ì„¸ì…˜ ìƒíƒœì— í•´ë‹¹ keyê°€ ì—†ìœ¼ë©´
            st.session_state[key] = value  # â† ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒˆë¡œ ì €ì¥

# ğŸ“Œ ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ë¥¼ Streamlitì— ì¶œë ¥í•˜ê³  ê¸°ë¡
def chat_message_user(prompt: str) -> dict:
    with st.chat_message("user"):  # â† ì‚¬ìš©ì ë©”ì‹œì§€ ë¸”ë¡
        st.markdown(prompt)  # â† ì‚¬ìš©ì ì…ë ¥ ì¶œë ¥
        return dict(role="user", content=prompt)  # â† ê¸°ë¡ìš© ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

# ğŸ“Œ LLM ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì¶œë ¥
def chat_message_llm_stream(role: str, model: str, messages: list) -> dict:
    with st.chat_message(role):  # â† "assistant" ì—­í• ë¡œ ë©”ì‹œì§€ ì¶œë ¥
        with st.spinner("ëŒ€í™”ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):  # â† ë¡œë”© ìŠ¤í”¼ë„ˆ í‘œì‹œ

            # ollama.chat(): LLMì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ëƒ„, stream=True ì˜µì…˜ í•„ìˆ˜!
            stream = ollama.chat(model=model, messages=messages, stream=True)

            # ì œë„¤ë ˆì´í„° í•¨ìˆ˜: ìŠ¤íŠ¸ë¦¼ ì‘ë‹µì„ í•˜ë‚˜ì”© ì½ì–´ì˜´
            def stream_parser(stream):
                for chunk in stream:
                    yield chunk["message"]["content"]  # â† ì‹¤ì œ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ

            # ğŸ“Œ Streamlitì—ì„œ ì œë„¤ë ˆì´í„°ë¡œ ë©”ì‹œì§€ ì¶œë ¥
            content = st.write_stream(stream_parser(stream))  # â† ì‹¤ì‹œê°„ ì¶œë ¥
            return dict(role="assistant", content=content)  # â† ê¸°ë¡ìš© ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

# ------------------- ë©”ì¸ ì½”ë“œ ì˜ì—­ -------------------
if __name__ == "__main__":
    st.set_page_config(layout="wide")
    st.title("ğŸ¤– ë§Œë“¤ë©´ì„œ ë°°ìš°ëŠ” ì±—ë´‡")

    # ğŸ“Œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”: ì´ì „ ëŒ€í™” ì €ì¥ìš© msgsì™€ ì‹¤í–‰ í”Œë˜ê·¸ running
    init_session_state(dict(msgs=[], running=False))
    msgs: list = st.session_state["msgs"]
    running: bool = st.session_state["running"]

    # ğŸ“Œ ì‚¬ìš©ìê°€ promptë¥¼ ì…ë ¥í–ˆëŠ”ì§€ ì—¬ë¶€ í™•ì¸í•˜ì—¬ running ì„¤ì •
    if "prompt" in st.session_state and st.session_state["prompt"] is not None:
        running = True
    else:
        running = False

    # ğŸ“Œ ì´ì „ ëŒ€í™” ë‚´ìš© ë‹¤ì‹œ ì¶œë ¥ (í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ ì‹œ ìœ ì§€ë¨)
    for row in msgs:
        with st.chat_message(row["role"]):
            st.markdown(row["content"])

    # ğŸ“Œ ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„±
    #   disabled â†’ runningì´ Trueë©´ ì…ë ¥ì°½ ë¹„í™œì„±í™”ë¨
    #   key â†’ prompt ì…ë ¥ì„ session_stateë¡œ ì¶”ì 
    if prompt := st.chat_input("ëŒ€í™”ë¥¼ ì…ë ¥í•˜ì„¸ìš”!", disabled=running, key="promph"):
        msg_user = chat_message_user(prompt)
        msgs.append(msg_user)  # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥

        # ğŸ“Œ LLM í˜¸ì¶œ (ëª¨ë¸ ì´ë¦„ì€ ì˜ˆì‹œë¡œ "gemma2:9b")
        msg_llm = chat_message_llm_stream("assistant", "gemma2:9b", msgs)
        msgs.append(msg_llm)  # ì‘ë‹µ ë©”ì‹œì§€ ì €ì¥

        # ğŸ“Œ ëŒ€í™”ê°€ ëë‚œ ë’¤ ì•±ì„ ë‹¤ì‹œ ì‹¤í–‰ (running ê°’ ë“± ê°±ì‹ )
        st.rerun()
