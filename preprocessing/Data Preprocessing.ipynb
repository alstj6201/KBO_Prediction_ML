{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d784488",
   "metadata": {},
   "source": [
    "## csv 파일 concat 전 전처리 코드\n",
    "\n",
    "1. 각 파일에서 연도 추출하여 GameID에 붙이기\n",
    "2. 날짜 변환 및 정렬\n",
    "3. 문자형 컬럼을 숫자형 컬럼으로 변환\n",
    "4. 승/패/무 + 홈/어웨이 정보 저장\n",
    "5. 무승부 제거 (이진 분류 예측을 위함)\n",
    "6. 팀 이름 숫자로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_baseball_data_and_save(file_paths, output_path):\n",
    "    # 여러 csv 파일을 읽어 하나의 DataFrame으로 합침\n",
    "    df_total = pd.concat([pd.read_csv(fp) for fp in file_paths], ignore_index=True)\n",
    "\n",
    "    # 각 파일에서 연도 추출하여 GameID에 붙이기\n",
    "    for fp in file_paths:\n",
    "        year = fp.split('_')[0]\n",
    "        mask = df_total['GameID'].isin(pd.read_csv(fp)['GameID'])\n",
    "        df_total.loc[mask, 'GameID'] = year + '-' + df_total.loc[mask, 'GameID']\n",
    "\n",
    "    # 날짜 변환 및 정렬\n",
    "    df_total['GameDate'] = pd.to_datetime(df_total['GameID'], errors='coerce')\n",
    "\n",
    "\n",
    "    # 문자열 분할하여 숫자형 컬럼으로 변환\n",
    "    df_total[['GO', 'FO']] = df_total['GO-FO'].str.split('-', expand=True).astype(int)\n",
    "    df_total[['NP_total', 'NP_strike']] = df_total['NP-S'].str.split('-', expand=True).astype(int)\n",
    "    df_total[['IR', 'IS']] = df_total['IR-IS'].str.split('-', expand=True).astype(int)\n",
    "    df_total.drop(columns=['GO-FO', 'NP-S', 'IR-IS'], inplace=True)\n",
    "\n",
    "    # 승/패/무 생성 + 홈/어웨이 정보 저장\n",
    "    results = []\n",
    "    home_away = []\n",
    "    for i in range(0, len(df_total), 2):\n",
    "        r1 = df_total.loc[i, 'R']\n",
    "        r2 = df_total.loc[i+1, 'R']\n",
    "        if r1 > r2:\n",
    "            results.extend([1, 0])\n",
    "        elif r1 < r2:\n",
    "            results.extend([0, 1])\n",
    "        else:\n",
    "            results.extend([-1, -1])\n",
    "        home_away.extend([0, 1])\n",
    "    df_total['Result'] = results\n",
    "    df_total['home_away'] = home_away\n",
    "\n",
    "    # 무승부 제거 (두 줄 모두 제거)\n",
    "    draw_indices = df_total[df_total['Result'] == -1].index\n",
    "    paired_draw_indices = draw_indices.union(draw_indices + (-1) ** (draw_indices % 2 == 0))\n",
    "    df_total = df_total.drop(paired_draw_indices).reset_index(drop=True)\n",
    "\n",
    "    # GameID 제거, GameDate를 맨 앞으로\n",
    "    df_total.drop(columns=['GameID'], inplace=True)\n",
    "    cols = ['GameDate'] + [col for col in df_total.columns if col != 'GameDate']\n",
    "    df_total = df_total[cols]\n",
    "\n",
    "    # 팀 이름 숫자로 인코딩\n",
    "    team_mapping = {\n",
    "        'KIA': 0, '두산': 1, '삼성': 2, '키움': 3, '롯데': 4,\n",
    "        'SSG': 5, '한화': 6, 'KT': 7, 'LG': 8, 'NC': 9\n",
    "    }\n",
    "    df_total['Team'] = df_total['Team'].replace(team_mapping)\n",
    "\n",
    "    df_total = df_total.sort_values('GameDate', kind='stable').reset_index(drop=True)\n",
    "\n",
    "    # 저장\n",
    "    df_total.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✅ 저장 완료: {output_path}\")\n",
    "\n",
    "# 사용 예시\n",
    "file_paths = ['2025_03_total.csv', '2025_04_total.csv', '2025_05_total.csv']  # 또는 실제 경로로 변경\n",
    "output_path = 'processed_baseball_2025.csv'\n",
    "preprocess_baseball_data_and_save(file_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010c3dc",
   "metadata": {},
   "source": [
    "## csv 파일 \"인코딩 깨졌을 경우\" concat 전 전처리 코드\n",
    "\n",
    "1. 각 파일에서 연도 추출하여 GameID에 붙이기\n",
    "2. 날짜 변환 및 정렬\n",
    "3. 문자형 컬럼을 숫자형 컬럼으로 변환\n",
    "4. 승/패/무 + 홈/어웨이 정보 저장\n",
    "5. 무승부 제거 (이진 분류 예측을 위함)\n",
    "6. 팀 이름 숫자로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe70ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023_total.csv\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     54\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_baseball_2023.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mpreprocess_baseball_data_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m, in \u001b[0;36mpreprocess_baseball_data_and_save\u001b[1;34m(file_paths, output_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_baseball_data_and_save\u001b[39m(file_paths, output_path):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 여러 csv 파일을 읽어 하나의 DataFrame으로 합침\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     df_total \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m file_paths], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 각 파일에서 연도 추출하여 GameID에 붙이기\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m file_paths:\n",
      "File \u001b[1;32mc:\\Users\\82109\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\82109\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\82109\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\82109\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\82109\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_baseball_data_and_save(file_paths, output_path):\n",
    "    # 여러 csv 파일을 읽어 하나의 DataFrame으로 합침\n",
    "    df_total = pd.concat([pd.read_csv(fp) for fp in file_paths], ignore_index=True)\n",
    "\n",
    "    # 각 파일에서 연도 추출하여 GameID에 붙이기\n",
    "    for fp in file_paths:\n",
    "        year = fp.split('_')[0]\n",
    "        mask = df_total['GameID'].isin(pd.read_csv(fp)['GameID'])\n",
    "        df_total.loc[mask, 'GameID'] = year + '-' + df_total.loc[mask, 'GameID']\n",
    "\n",
    "    # 날짜 변환 및 정렬\n",
    "    df_total['GameDate'] = pd.to_datetime(df_total['GameID'])\n",
    "    df_total = df_total.sort_values('GameDate').reset_index(drop=True)\n",
    "\n",
    "    # 문자열 분할하여 숫자형 컬럼으로\n",
    "    df_total[['GO', 'FO']] = df_total['GO-FO'].str.split('-', expand=True).astype(int)\n",
    "    df_total[['NP_total', 'NP_strike']] = df_total['NP-S'].str.split('-', expand=True).astype(int)\n",
    "    df_total[['IR', 'IS']] = df_total['IR-IS'].str.split('-', expand=True).astype(int)\n",
    "    df_total.drop(columns=['GO-FO', 'NP-S', 'IR-IS'], inplace=True)\n",
    "\n",
    "    # 팀 One-Hot Encoding\n",
    "    df_total = pd.get_dummies(df_total, columns=['Team'])\n",
    "\n",
    "    # 승/패/무승부 결과 생성\n",
    "    results = []\n",
    "    for i in range(0, len(df_total), 2):\n",
    "        r1 = df_total.loc[i, 'R']\n",
    "        r2 = df_total.loc[i+1, 'R']\n",
    "        if r1 > r2:\n",
    "            results.extend([1, 0])\n",
    "        elif r1 < r2:\n",
    "            results.extend([0, 1])\n",
    "        else:\n",
    "            results.extend([-1, -1])\n",
    "    df_total['Result'] = results\n",
    "\n",
    "    # Team_ 컬럼의 bool 값을 1/0으로 변환\n",
    "    team_cols = [col for col in df_total.columns if col.startswith(\"Team_\")]\n",
    "    df_total[team_cols] = df_total[team_cols].astype(int)\n",
    "\n",
    "    # GameID 열 제거, GameDate를 맨 앞으로 이동\n",
    "    df_total.drop(columns=['GameID'], inplace=True)\n",
    "    cols = ['GameDate'] + [col for col in df_total.columns if col != 'GameDate']\n",
    "    df_total = df_total[cols]\n",
    "\n",
    "    # 전처리된 결과 저장\n",
    "    df_total.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✅ 저장 완료: {output_path}\")\n",
    "\n",
    "# 사용 예시\n",
    "file_paths = ['2023_total.txt']\n",
    "output_path = 'processed_baseball_2023.csv'\n",
    "preprocess_baseball_data_and_save(file_paths, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ced1ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: processed_baseball_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:103: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('KIA',0,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:104: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('두산',1,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:105: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('삼성',2,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:106: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('키움',3,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:107: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('롯데',4,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('SSG',5,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:109: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('한화',6,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('KT',7,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:111: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('LG',8,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:112: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_total['Team'].replace('NC',9,inplace = True)\n",
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_3052\\448309069.py:112: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_total['Team'].replace('NC',9,inplace = True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def extract_year_from_filename(filepath):\n",
    "    basename = os.path.basename(filepath)  # 경로에서 파일명만 추출\n",
    "    match = re.match(r'(\\d{4})_', basename)  # '2024_' 형식에만 일치\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        raise ValueError(f\"파일명에서 연도를 찾을 수 없습니다: {filepath}\")\n",
    "    \n",
    "\n",
    "# GameID를 날짜 문자열로 변환 ('03월 23일' + '2024' → '2024-03-23')\n",
    "def convert_korean_gameid_to_date(gameid, year):\n",
    "    match = re.match(r'0?(\\d{1,2})월 0?(\\d{1,2})일', str(gameid))\n",
    "    if match:\n",
    "        return f\"{year}-{int(match.group(1)):02}-{int(match.group(2)):02}\"\n",
    "    return None\n",
    "\n",
    "# '09월 13일' 같은 날짜를 '9-13' 형식으로 변환\n",
    "def convert_korean_date_to_numeric(value):\n",
    "    match = re.match(r'0?(\\d{1,2})월 0?(\\d{1,2})일', str(value))\n",
    "    if match:\n",
    "        return f\"{int(match.group(1))}-{int(match.group(2))}\"\n",
    "    return value\n",
    "\n",
    "# 엑셀에서 망가진 값 예외 처리 ('Oct-85' → '10-13')\n",
    "def fix_common_garbage_gofo(val):\n",
    "    if val == 'Oct-85':\n",
    "        return '10-13'\n",
    "    return val\n",
    "\n",
    "# 'x-y' 형식을 안전하게 정수 쌍으로 분리\n",
    "def safe_split_to_int_pair(val):\n",
    "    try:\n",
    "        parts = str(val).split('-')\n",
    "        if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():\n",
    "            return int(parts[0]), int(parts[1])\n",
    "    except:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "# 전체 전처리 함수\n",
    "def preprocess_baseball_data_and_save(file_paths, output_path):\n",
    "    combined = []\n",
    "\n",
    "    for fp in file_paths:\n",
    "        year = extract_year_from_filename(fp)  # 연도 추출\n",
    "        df = pd.read_csv(fp, encoding='utf-16', sep='\\t')\n",
    "        df['GameDate'] = df['GameID'].apply(lambda x: convert_korean_gameid_to_date(x, year))\n",
    "        combined.append(df)\n",
    "\n",
    "        # GameID → GameDate 변환\n",
    "        df['GameDate'] = df['GameID'].apply(lambda x: convert_korean_gameid_to_date(x, year))\n",
    "        combined.append(df)\n",
    "\n",
    "    df_total = pd.concat(combined, ignore_index=True)\n",
    "    df_total['GameDate'] = pd.to_datetime(df_total['GameDate'], errors='coerce')\n",
    "    #df_total = df_total.sort_values('GameDate').reset_index(drop=True)\n",
    "\n",
    "    # 날짜형식 처리 + 잘못된 값 보정\n",
    "    for col in ['GO-FO', 'NP-S', 'IR-IS']:\n",
    "        df_total[col] = df_total[col].apply(convert_korean_date_to_numeric)\n",
    "        df_total[col] = df_total[col].apply(fix_common_garbage_gofo)\n",
    "\n",
    "    # 문자열 쌍 → 숫자형 컬럼으로 분리\n",
    "    df_total[['GO', 'FO']] = df_total['GO-FO'].apply(lambda x: pd.Series(safe_split_to_int_pair(x)))\n",
    "    df_total[['NP_total', 'NP_strike']] = df_total['NP-S'].apply(lambda x: pd.Series(safe_split_to_int_pair(x)))\n",
    "    df_total[['IR', 'IS']] = df_total['IR-IS'].apply(lambda x: pd.Series(safe_split_to_int_pair(x)))\n",
    "    df_total.drop(columns=['GO-FO', 'NP-S', 'IR-IS'], inplace=True)\n",
    "\n",
    "    # 승/패/무 결과 계산\n",
    "    results = []\n",
    "    home_away = []\n",
    "\n",
    "    for i in range(0, len(df_total), 2):\n",
    "        r1 = df_total.loc[i, 'R']\n",
    "        r2 = df_total.loc[i+1, 'R']\n",
    "        if r1 > r2:\n",
    "            results.extend([1, 0])\n",
    "        elif r1 < r2:\n",
    "            results.extend([0, 1])\n",
    "        else:\n",
    "            results.extend([-1, -1])\n",
    "        home_away.extend([0,1])\n",
    "    df_total['Result'] = results\n",
    "    df_total['home_away'] = home_away\n",
    "\n",
    "\n",
    "    # 무승부 제거 (두 줄 모두 제거)\n",
    "    draw_indices = df_total[df_total['Result'] == -1].index\n",
    "    paired_draw_indices = draw_indices.union(draw_indices + (-1) ** (draw_indices % 2 == 0))\n",
    "    df_total = df_total.drop(paired_draw_indices).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # GameID 제거, GameDate를 앞으로 이동\n",
    "    df_total.drop(columns=['GameID'], inplace=True)\n",
    "    cols = ['GameDate'] + [col for col in df_total.columns if col != 'GameDate']\n",
    "    df_total = df_total[cols]\n",
    "\n",
    "    \n",
    "    df_total['Team'].replace('KIA',0,inplace = True)\n",
    "    df_total['Team'].replace('두산',1,inplace = True)\n",
    "    df_total['Team'].replace('삼성',2,inplace = True)\n",
    "    df_total['Team'].replace('키움',3,inplace = True)\n",
    "    df_total['Team'].replace('롯데',4,inplace = True)\n",
    "    df_total['Team'].replace('SSG',5,inplace = True)\n",
    "    df_total['Team'].replace('한화',6,inplace = True)\n",
    "    df_total['Team'].replace('KT',7,inplace = True)\n",
    "    df_total['Team'].replace('LG',8,inplace = True)\n",
    "    df_total['Team'].replace('NC',9,inplace = True)\n",
    "\n",
    "    # CSV로 저장 (한글 깨짐 방지용 utf-8-sig)\n",
    "    df_total.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✅ 저장 완료: {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "file_paths = ['2023_total.csv']\n",
    "output_path = 'processed_baseball_2023.csv'\n",
    "preprocess_baseball_data_and_save(file_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbb62d",
   "metadata": {},
   "source": [
    "## csv 파일 concat 코드\n",
    "\n",
    "연도별로 모은 csv 파일을 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad8ca33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: processed_baseball_total.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def preprocess_baseball_data_and_save(file_paths, output_path):\n",
    "    # 여러 csv 파일을 읽어 하나의 DataFrame으로 합침\n",
    "    df_total = pd.concat([pd.read_csv(fp) for fp in file_paths], ignore_index=True)\n",
    "\n",
    "    df_total.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✅ 저장 완료: {output_path}\")\n",
    "\n",
    "# 사용 예시\n",
    "file_paths = ['processed_2122.csv', 'processed_baseball_2023.csv', 'processed_2425.csv']  # 또는 실제 경로로 변경\n",
    "output_path = 'processed_baseball_total.csv'\n",
    "preprocess_baseball_data_and_save(file_paths, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bbb57c",
   "metadata": {},
   "source": [
    "## rolling & 최근 전적 column 생성 코드\n",
    "\n",
    "rolling(5)를 통해 미래의 야구 승패도 rolling을 사용하여 feature을 만들어 적용할 수 있게 함.\n",
    "최근 전적을 비교하여 야구 승패를 보다 쉽게 예측 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53c491c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: ../data/rolling_only.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_and_save_rolling_only(file_paths, output_path):\n",
    "    # 파일 합치기\n",
    "    df_total = pd.concat([pd.read_csv(fp) for fp in file_paths], ignore_index=True)\n",
    "\n",
    "    # 최근 5경기 승/패 전적 계산\n",
    "    recent_wins = []\n",
    "    recent_losses = []\n",
    "    match_history = {}\n",
    "\n",
    "    for i in range(0, len(df_total), 2):\n",
    "        row1 = df_total.iloc[i]\n",
    "        row2 = df_total.iloc[i + 1]\n",
    "\n",
    "        t1, t2 = row1['Team'], row2['Team']\n",
    "        key = tuple(sorted((t1, t2)))\n",
    "\n",
    "        history = match_history.get(key, [])\n",
    "        wins_t1 = history.count((t1, 1))\n",
    "        wins_t2 = history.count((t2, 1))\n",
    "\n",
    "        recent_wins.extend([wins_t1, wins_t2])\n",
    "        recent_losses.extend([wins_t2, wins_t1])\n",
    "\n",
    "        if row1['Result'] == 1:\n",
    "            history.append((t1, 1))\n",
    "        elif row2['Result'] == 1:\n",
    "            history.append((t2, 1))\n",
    "\n",
    "        match_history[key] = history[-5:]\n",
    "\n",
    "    df_total['Recent_5_Win'] = recent_wins\n",
    "    df_total['Recent_5_Loss'] = recent_losses\n",
    "\n",
    "    # 수치형 컬럼에서 제외할 항목\n",
    "    numeric_cols = df_total.select_dtypes(include='number').columns.tolist()\n",
    "    exclude_cols = ['Result', 'home_away', 'Recent_5_Win', 'Recent_5_Loss', 'WPA_p', 'RE24_p', 'WPA_b', 'RE24_b', 'AVG', 'OPS', 'GDP', 'LOB', 'GSC', 'LI_b', 'LI_p', 'IR', 'IS', 'HBP', 'HBP_p'] # 여기에 제외할 열 이름 적으면 됨\n",
    "    rolling_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "\n",
    "    # 팀별 rolling 평균\n",
    "    df_rolled = (\n",
    "        df_total.groupby('Team')[rolling_cols]\n",
    "        .rolling(window=5, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df_rolled.columns = [f\"{col}\" for col in df_rolled.columns]\n",
    "\n",
    "    # 필요한 컬럼만 포함\n",
    "    df_base = df_total[['GameDate', 'Team']].copy()\n",
    "    non_rolling_cols = df_total[exclude_cols]\n",
    "\n",
    "    # 2. rolling 결과와 함께 병합\n",
    "    df_result = pd.concat([\n",
    "        df_base.reset_index(drop=True),\n",
    "        non_rolling_cols.reset_index(drop=True),\n",
    "        df_rolled.reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "\n",
    "    \n",
    "    # 컬럼 순서 맞추기\n",
    "    desired_order = [\n",
    "        'GameDate', 'Team', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'BB', 'HBP', 'SO',\n",
    "        'GO', 'FO', 'NP', 'GDP', 'LOB', 'AVG', 'OPS', 'LI_b', 'WPA_b', 'RE24_b',\n",
    "        'IP', 'TBF', 'H_p', 'R_p', 'ER', 'BB_p', 'HBP_p', 'K', 'HR_p', 'GSC',\n",
    "        'ERA', 'WHIP', 'LI_p', 'WPA_p', 'RE24_p', 'NP_total', 'NP_strike',\n",
    "        'IR', 'IS', 'home_away', 'Recent_5_Win', 'Recent_5_Loss', 'Result'\n",
    "    ]\n",
    "    df_result = df_result[[col for col in desired_order if col in df_result.columns]]\n",
    "\n",
    "    \n",
    "    # CSV로 저장\n",
    "    df_result.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✅ 저장 완료: {output_path}\")\n",
    "\n",
    "# 사용 예시\n",
    "file_paths = ['../data/concat_data.csv']\n",
    "output_path = '../data/rolling_only.csv'\n",
    "preprocess_and_save_rolling_only(file_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be28c0dd",
   "metadata": {},
   "source": [
    "## 최근 전적 column 생성 코드\n",
    "\n",
    "rolling(5)를 통해 미래의 야구 승패도 rolling을 사용하여 feature을 만들어 적용할 수 있게 함.\n",
    "최근 전적을 비교하여 야구 승패를 보다 쉽게 예측 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f44bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: ../data/not_rolling_only.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_and_save_basic(file_paths, output_path):\n",
    "    # 1. CSV 파일들 합치기\n",
    "    df_total = pd.concat([pd.read_csv(fp) for fp in file_paths], ignore_index=True)\n",
    "\n",
    "    # 2. 최근 5경기 승/패 전적 계산\n",
    "    recent_wins = []\n",
    "    recent_losses = []\n",
    "    match_history = {}\n",
    "\n",
    "    for i in range(0, len(df_total), 2):\n",
    "        row1 = df_total.iloc[i]\n",
    "        row2 = df_total.iloc[i + 1]\n",
    "\n",
    "        t1, t2 = row1['Team'], row2['Team']\n",
    "        key = tuple(sorted((t1, t2)))\n",
    "\n",
    "        history = match_history.get(key, [])\n",
    "        wins_t1 = history.count((t1, 1))\n",
    "        wins_t2 = history.count((t2, 1))\n",
    "\n",
    "        recent_wins.extend([wins_t1, wins_t2])\n",
    "        recent_losses.extend([wins_t2, wins_t1])\n",
    "\n",
    "        if row1['Result'] == 1:\n",
    "            history.append((t1, 1))\n",
    "        elif row2['Result'] == 1:\n",
    "            history.append((t2, 1))\n",
    "\n",
    "        match_history[key] = history[-5:]\n",
    "\n",
    "    df_total['Recent_5_Win'] = recent_wins\n",
    "    df_total['Recent_5_Loss'] = recent_losses\n",
    "\n",
    "    # 3. 컬럼 순서 맞추기\n",
    "    desired_order = [\n",
    "        'GameDate', 'Team', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'BB', 'HBP', 'SO',\n",
    "        'GO', 'FO', 'NP', 'GDP', 'LOB', 'AVG', 'OPS', 'LI_b', 'WPA_b', 'RE24_b',\n",
    "        'IP', 'TBF', 'H_p', 'R_p', 'ER', 'BB_p', 'HBP_p', 'K', 'HR_p', 'GSC',\n",
    "        'ERA', 'WHIP', 'LI_p', 'WPA_p', 'RE24_p', 'NP_total', 'NP_strike',\n",
    "        'IR', 'IS', 'home_away', 'Recent_5_Win', 'Recent_5_Loss', 'Result'\n",
    "    ]\n",
    "    df_total = df_total[[col for col in desired_order if col in df_total.columns]]\n",
    "\n",
    "    # 4. CSV로 저장\n",
    "    df_total.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✅ 저장 완료: {output_path}\")\n",
    "\n",
    "# 사용 예시\n",
    "file_paths = ['../data/concat_data.csv']\n",
    "output_path = '../data/not_rolling_only.csv'\n",
    "preprocess_and_save_basic(file_paths, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4d502",
   "metadata": {},
   "source": [
    "## 특정 column 삭제 코드\n",
    "\n",
    "correalation matrix와 다중공선성을 계산한 후 필요없는 column들을 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fc49570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 16개 변수 선택 및 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. CSV 불러오기\n",
    "df_total = pd.read_csv('../data/rolling_only.csv')  # ← 여기에 실제 파일명 입력\n",
    "\n",
    "# 2. 최종 선택된 16개 변수만 선택\n",
    "selected_columns = ['GameDate', 'Team',\n",
    "    'OPS', 'BB', 'HBP', 'SO',         # 타자 성과\n",
    "    'ERA', 'BB_p', 'K', 'IR', 'IS', 'TBF',  # 투수 성과\n",
    "    'Recent_5_Win', 'Recent_5_Loss',  # 최근 경기 흐름\n",
    "    'home_away', 'Result'                   # 홈/원정 정보\n",
    "]\n",
    "\n",
    "# 3. 해당 변수만 남기고 나머지 제거\n",
    "df_selected = df_total[selected_columns].copy()\n",
    "\n",
    "# 4. 결과를 새 파일로 저장\n",
    "df_selected.to_csv('../data/final_data_rolling.csv', index=False, encoding='utf-8-sig')  # ← 저장 파일명 지정\n",
    "\n",
    "print(\"✅ 16개 변수 선택 및 저장 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff9820",
   "metadata": {},
   "source": [
    "## 팀 당 row를 경기 당 row로로\n",
    "\n",
    "합쳐용~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fc13ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 컬럼 붙이기 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_new = pd.read_csv(\"../data/final_data_rolling.csv\")\n",
    "\n",
    "games = []\n",
    "for i in range(0, len(df_new), 2):\n",
    "\n",
    "    if df_new.loc[i, 'home_away'] == 0:\n",
    "        home = df_new.iloc[i+1]\n",
    "        away = df_new.iloc[i]\n",
    "    else:\n",
    "        home = df_new.iloc[i]\n",
    "        away = df_new.iloc[i + 1]\n",
    "\n",
    "    # 새로운 경기 단위 row 생성\n",
    "    game_row = {\n",
    "        'GameDate': home['GameDate'],\n",
    "        'home_Team': home['Team'],\n",
    "        'away_Team': away['Team'],\n",
    "        'home_win': int(home['Result'] > away['Result']) , # 홈팀이 이기면 1, 지면 0\n",
    "        'home_Recent_5_Win': home['Recent_5_Win'],\n",
    "        'home_Recent_5_Loss': home['Recent_5_Loss']\n",
    "    }\n",
    "\n",
    "    # 제외할 열\n",
    "    excluded_cols = ['GameDate', 'Team', 'Result','home_away','Recent_5_Win','Recent_5_Loss']\n",
    "\n",
    "    # 홈팀 feature 추가\n",
    "    for col in df_new.columns:\n",
    "        if col not in excluded_cols:\n",
    "            game_row[f'home_{col}'] = home[col]\n",
    "\n",
    "    # 원정팀 feature 추가\n",
    "    for col in df_new.columns:\n",
    "        if col not in excluded_cols:\n",
    "            game_row[f'away_{col}'] = away[col]\n",
    "\n",
    "    games.append(game_row)\n",
    "\n",
    "# 새로운 데이터프레임으로 변환\n",
    "df_game_unit = pd.DataFrame(games)\n",
    "\n",
    "\n",
    "df_game_unit.to_csv('../data/real_final.csv', index=False, encoding='utf-8-sig')  # ← 저장 파일명 지정\n",
    "\n",
    "print(\"✅ 컬럼 붙이기 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39130a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
